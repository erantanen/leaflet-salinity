{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-16T14:04:51.999526200Z",
     "start_time": "2024-04-16T14:02:40.580555100Z"
    },
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import csv\n",
    "import pre_proc_depth_id as pre\n",
    "\n",
    "def open_csv(proc_file):\n",
    "    # data = pre.data_to_proc(proc_file, proc_fields)\n",
    "    # this is the consolidated csv just read each line\n",
    "    data_b = os.path.join(os.getcwd(), \"input\", proc_file)\n",
    "    return pd.read_csv(data_b)\n",
    "\n",
    "\n",
    "# fields = ['date', 'lat', 'long', 'Depthm', 'T_degC', 'Salnty']\n",
    "csv_data_new = open_csv(\"data_everything.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d884d6f846b64f20",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-16T14:26:21.892084500Z",
     "start_time": "2024-04-16T14:26:21.692545Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_current = csv_data_new\n",
    "\n",
    "\n",
    "lat_1 = 40\n",
    "lat_2 = 48\n",
    "lon_1 = -135\n",
    "lon_2 = -123\n",
    "d_1 = 0\n",
    "d_2 = 900\n",
    "cond_1a = df_current.lat.between(lat_1,lat_2)\n",
    "cond_1b = df_current.long.between(lon_1,lon_2)\n",
    "cond_2 = df_current.date.str.startswith(\"194\")\n",
    "cond_3 = (df_current.Depthm.notnull() & df_current.T_degC.notnull()&df_current.Salnty.notnull())\n",
    "\n",
    "cond_4 = df_current.Depthm.between(d_1,d_2)\n",
    "result_1 = df_current.loc[ cond_1a & cond_1b & cond_2 & cond_3 & cond_4]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "de2ef3cd75503306",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-16T14:26:24.888244500Z",
     "start_time": "2024-04-16T14:26:24.853469600Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 5105 entries, 2160 to 25565\n",
      "Data columns (total 6 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   date    5105 non-null   object \n",
      " 1   lat     5105 non-null   float64\n",
      " 2   long    5105 non-null   float64\n",
      " 3   Depthm  5105 non-null   int64  \n",
      " 4   T_degC  5105 non-null   float64\n",
      " 5   Salnty  5105 non-null   float64\n",
      "dtypes: float64(4), int64(1), object(1)\n",
      "memory usage: 279.2+ KB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>Depthm</th>\n",
       "      <th>T_degC</th>\n",
       "      <th>Salnty</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2160</th>\n",
       "      <td>1949-04</td>\n",
       "      <td>40.768716</td>\n",
       "      <td>-124.788358</td>\n",
       "      <td>0</td>\n",
       "      <td>10.30</td>\n",
       "      <td>33.030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2161</th>\n",
       "      <td>1949-04</td>\n",
       "      <td>40.768716</td>\n",
       "      <td>-124.788358</td>\n",
       "      <td>6</td>\n",
       "      <td>18.46</td>\n",
       "      <td>32.920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2162</th>\n",
       "      <td>1949-04</td>\n",
       "      <td>40.768716</td>\n",
       "      <td>-124.788358</td>\n",
       "      <td>10</td>\n",
       "      <td>10.29</td>\n",
       "      <td>32.951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2163</th>\n",
       "      <td>1949-04</td>\n",
       "      <td>40.768716</td>\n",
       "      <td>-124.788358</td>\n",
       "      <td>15</td>\n",
       "      <td>10.29</td>\n",
       "      <td>32.990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2164</th>\n",
       "      <td>1949-04</td>\n",
       "      <td>40.768716</td>\n",
       "      <td>-124.788358</td>\n",
       "      <td>20</td>\n",
       "      <td>10.33</td>\n",
       "      <td>33.005</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date        lat        long  Depthm  T_degC  Salnty\n",
       "2160  1949-04  40.768716 -124.788358       0   10.30  33.030\n",
       "2161  1949-04  40.768716 -124.788358       6   18.46  32.920\n",
       "2162  1949-04  40.768716 -124.788358      10   10.29  32.951\n",
       "2163  1949-04  40.768716 -124.788358      15   10.29  32.990\n",
       "2164  1949-04  40.768716 -124.788358      20   10.33  33.005"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_1.info()\n",
    "result_1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "22433f2356775dec",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-22T22:50:20.616147800Z",
     "start_time": "2024-04-22T22:50:20.303742300Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import netCDF4\n",
    "\n",
    "def geo_idx(dd, dd_array):\n",
    "    #\n",
    "    #   returns the index of the closest degrees decimal value in the array.\n",
    "    #   dd = degrees decimal (Float64)\n",
    "    #   dd_array = arrach of degrees decimal values (Float64)\n",
    "    #\n",
    "    #\n",
    "    geo_index = (np.abs(dd_array - dd)).argmin()\n",
    "    return geo_index\n",
    "\n",
    "def open_GEBCO_file(filepath):\n",
    "    #\n",
    "    #   returns dataset in NetCDF format and from the\n",
    "    #   dataset arrays of the latitudes and longitudes\n",
    "    #   filepath = filepath to GEBCO file\n",
    "    #\n",
    "    #\n",
    "    NetCDF_dataset = netCDF4.Dataset(filepath)\n",
    "    lats = NetCDF_dataset.variables['lat'][:]\n",
    "    lons = NetCDF_dataset.variables['lon'][:]\n",
    "    return NetCDF_dataset, lats, lons\n",
    "\n",
    "def get_GEBCO_info(dataset):\n",
    "    #\n",
    "    #   prints metadata in GEBCO file\n",
    "    #\n",
    "    #\n",
    "    print(dataset.data_model)\n",
    "\n",
    "    for attr in dataset.ncattrs():\n",
    "        print(attr, '=', getattr(dataset, attr))\n",
    "\n",
    "    print(dataset.variables)\n",
    "    return\n",
    "\n",
    "def get_elevation(lat, lon):\n",
    "    #\n",
    "    # returns the elevation given a latitude and longitude\n",
    "    #\n",
    "    lat_index = geo_idx(lat, lats)\n",
    "    lon_index = geo_idx(lon, lons)\n",
    "    return gebco.variables['elevation'][lat_index, lon_index]\n",
    "\n",
    "#\n",
    "\n",
    "gebco, lats, lons  = open_GEBCO_file('GEBCO_2023_sub_ice_topo.nc')\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "25971f32-cb55-44c8-83cf-28c047f54b86",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-22T22:51:53.956194900Z",
     "start_time": "2024-04-22T22:51:53.897827700Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92\n"
     ]
    }
   ],
   "source": [
    "print(get_elevation(43, -124))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [],
   "source": [
    "from gpx_converter import Converter\n",
    "\n",
    "\n",
    "# these are longitudinal ranges\n",
    "# if the numbers are \"neg\" then they have to be swap'd\n",
    "inc_end = -123\n",
    "inc_start= -135\n",
    "\n",
    "\n",
    "inc_step = 0.01\n",
    "\n",
    "list_of_lats = [40, 41, 42, 43, 44,45,46,47]\n",
    "\n",
    "lat_start = 40.6\n",
    "lat_end = 47.2\n",
    "\n",
    "\n",
    "def track_list(inc_start, inc_end, inc_step):\n",
    "    return np.arange(inc_start, inc_end, inc_step)\n",
    "\n",
    "\n",
    "def track_elevation_list( coord_list,lat_list ):\n",
    "    my_dict = {}\n",
    "    \n",
    "    for elm_lat in lat_list:\n",
    "        file_name = \"track_\" + str(elm_lat) + \".csv\"\n",
    "        gpx_file_name = \"track_\" + str(elm_lat) + \".gpx\"\n",
    "        \n",
    "        with open(file_name, 'w') as fh:\n",
    "            header= \"lat,lon,elev\\n\"\n",
    "            fh.write(header)\n",
    "            for elm_lon in coord_list:\n",
    "                elev = get_elevation(elm_lat,elm_lon)\n",
    "                data_dump = str(elm_lat) + \",\" + str(elm_lon) + \",\" +str(elev)+ \"\\n\"\n",
    "                #print(data_dump)\n",
    "                fh.write(data_dump)\n",
    "        \n",
    "        Converter(input_file=file_name).csv_to_gpx(lats_colname='lat',\n",
    "                                                 longs_colname='lon',\n",
    "                                                alts_colname='elev',\n",
    "                                                 output_file=gpx_file_name)\n",
    "                \n",
    "                \n",
    "                \n",
    "                \n",
    "                \n",
    "\n",
    "# creates tracks based on lat numbers dumps to csv named file\n",
    "c_list = track_list(inc_start, inc_end, inc_step)\n",
    "track_elevation_list(c_list,list_of_lats)\n",
    "    \n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-16T17:09:43.666748600Z",
     "start_time": "2024-04-16T17:09:38.456658200Z"
    }
   },
   "id": "bac06a2b4c954857"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "import simplekml\n",
    "import pandas\n",
    "\n",
    "df=pandas.read_csv(\"track_41.csv\")\n",
    "kml=simplekml.Kml()\n",
    "\n",
    "for lon,lat,elev in zip(df[\"lon\"],df[\"lat\"], df[\"elev\"]):\n",
    "    kml.newpoint(coords=[(lon,lat,elev)])\n",
    "\n",
    "kml.save((\"test.kml\"))\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-24T23:46:46.716239Z",
     "start_time": "2024-04-24T23:46:45.957398400Z"
    }
   },
   "id": "216a05d5100a451"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "track_40.gpx\n",
      "track_41.gpx\n",
      "track_42.gpx\n",
      "track_43.gpx\n",
      "track_44.gpx\n",
      "track_45.gpx\n",
      "track_46.gpx\n",
      "track_47.gpx\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import glob\n",
    "import gpx2kml\n",
    "\n",
    "gpx_list = glob.glob(\"*.gpx\")\n",
    "\n",
    "for each_gpx in gpx_list:\n",
    "    print(each_gpx)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-24T23:23:53.931355900Z",
     "start_time": "2024-04-24T23:23:53.916361100Z"
    }
   },
   "id": "97b6649bb860cbb0"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
